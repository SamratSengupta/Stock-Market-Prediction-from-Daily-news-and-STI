{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\numpy\\.libs\\libopenblas.noijjg62emaszi6nyurl6jbkm4evbgm7.gfortran-win_amd64.dll\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\softwares\\conda4.8.2-python3.7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import median_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.optim import Adam\n",
    "\n",
    "import os.path as osp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pytorch_transformers import *\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import os.path as osp\n",
    "\n",
    "from utils import normalize_price\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from sklearn import preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor ##Import Tabnet \n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import os.path as osp\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import median_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BertCapsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 17px;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 17px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = osp.join(Path(os.getcwd()).parent,'Data')\n",
    "model_path = osp.join(Path(os.getcwd()).parent,'Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_test_df = pd.read_csv(data_path + '/ensemble_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ens_test_df['Date'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'News', 'cap', 'stochaistic_k_percent',\n",
       "       'stochaistic_D', 'Momentum', 'rate_of_change', 'William_R_percent',\n",
       "       'AD_oscillator', 'Disparity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(model_path + '/ensemble-bert-capsule.pth')\n",
    "#ensemble bert capsule hyper parameters\n",
    "ebc_model = BertCapsule.bertCapsuleModel(input_dim_capsule=768,\n",
    "                                     num_capsule=10,dim_capsule=16,\n",
    "                                     routings=5,kernel_size=(9,1),\n",
    "                                     dropout_p=0.25,T_epsilon = 1e-7,\n",
    "                                     batch_size=128)\n",
    "ebc_model.state_dict = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "ebc_scaler = load(open(model_path + '/ensemble-bert-capsule-scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_headlines = ens_test_df['News'].tolist()\n",
    "norm_price = ebc_scaler.transform(ens_test_df['cap'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a721b1a576c4f4590de0f4a9cf6edb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=152.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 400\n",
    "batch_size = 4\n",
    "input_ids=[]\n",
    "\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in all_headlines]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "for i in tqdm_notebook(range(len(tokenized_texts))):\n",
    "       input_ids.append(tokenizer.convert_tokens_to_ids(tokenized_texts[i]))        \n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "#Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:    \n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "    \n",
    "test_inputs,test_labels = input_ids, norm_price\n",
    "test_masks, _ = attention_masks, input_ids\n",
    "test_inputs =  torch.from_numpy(np.array(test_inputs)).long()\n",
    "test_labels = torch.from_numpy(np.array(test_labels)).float()\n",
    "test_masks = torch.from_numpy(np.array(test_masks)).float()\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    ebc_model = ebc_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n",
      "output shape  torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "      # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "      # Forward pass\n",
    "        outputs = ebc_model.forward(b_input_ids,b_input_mask)\n",
    "      # print (outputs)target.\n",
    "        test_label = b_labels.cpu().data.numpy().tolist()\n",
    "        test_labels.append(test_label)\n",
    "        prediction = outputs.cpu().data.numpy().flatten().tolist()   \n",
    "        predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ebc_scaler.inverse_transform(predictions)[:, [0]].flatten()\n",
    "preds = preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbr_scaler = load(open(model_path + '/ensemble-tabnet-scaler.pkl', 'rb'))\n",
    "tbnt_regr = torch.load(model_path + '/ensemble-tabnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_test_df=ens_test_df.drop(['Unnamed: 0','News','Date'],axis=1)\n",
    "scaled_features = tbr_scaler.transform(ens_test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(scaled_features, index=ens_test_df.index, columns=ens_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cap'\n",
    "test_indices = test.index\n",
    "for col in test.columns[test.dtypes == 'float64']:\n",
    "    test.fillna(test.loc[test_indices, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "features = [ col for col in test.columns if col not in unused_feat+[target]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[features].values[test_indices]\n",
    "y_test = test[target].values[test_indices].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_predictions = tbnt_regr.predict(X_test)\n",
    "tb_preds = ebc_scaler.inverse_transform(tb_predictions)[:, [0]].flatten()\n",
    "tb_preds = tb_preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame.from_dict({'date':dates, 'cap' : ens_test_df['cap'],'ebc_pred' : preds ,'tb_pred':tb_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['final_pred'] = -0.0323106 * main_df['ebc_pred'] + 0.09788833 * main_df['tb_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df= main_df.drop(['ebc_pred','tb_pred',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = osp.join(Path(os.getcwd()).parent,'Results')\n",
    "main_df.to_csv(result_path + '/final_pred_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
